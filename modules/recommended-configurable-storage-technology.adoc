// Module included in the following assemblies:
//
// * storage/optimizing-storage.adoc

[id='recommended-configurable-storage-technology-{context}']
= Recommended configurable storage technology

The following table summarizes the recommended and configurable storage
technologies for the given {product-title} cluster application.

.Recommended and configurable storage technology
[options="header"]
|===
|Storage type |ROX footnoteref:[rox,ReadOnlyMany]|RWX footnoteref:[rwx,ReadWriteMany] |Registry|Scaled registry|Metrics|Logging|Apps

| Block
| Yes footnoteref:[disk,This does not apply to physical disk, VM physical disk, VMDK, loopback over NFS, AWS EBS, and Azure Disk.]
| No
| Configurable
| Not configurable
| Recommended
| Recommended
| Recommended

| File
| Yes footnoteref:[disk]
| Yes
| Configurable
| Configurable
| Configurable footnoteref:[metrics-warning,For metrics, it is an anti-pattern to use any shared storage and a single volume
(RWX). By default, metrics deploys with one volume per Cassandra Replica.]
| Configurable footnoteref:[logging-warning,For logging, using any shared
storage would be an anti-pattern. One volume per logging-es is required.]
| Recommended

| Object
| Yes
| Yes
| Recommended
| Recommended
| Not configurable
| Not configurable
| Not configurable footnoteref:[object,Object storage is not consumed through {product-title}'s PVs/persistent volume claims (PVCs). Apps must integrate with the object storage REST API. ]
|===

[NOTE]
====
A scaled registry is an {product-title} registry where three or more pod replicas are running.
====

== Specific application storage recommendations

[IMPORTANT]
====
Testing shows issues with using the NFS server on RHEL as storage backend for
the container image registry. This includes the OpenShift Container Registry and Quay, Cassandra
for metrics storage, and ElasticSearch for logging storage. Therefore, using NFS
to back PVs used by core services is not recommended.

Other NFS implementations on the marketplace might not have these issues.
Contact the individual NFS implementation vendor for more information on any
testing that was possibly completed against these OpenShift core components.
====

==== Registry

In a non-scaled/high-availability (HA) {product-title} registry cluster deployment:

* The preferred storage technology is object storage followed by block storage. The
storage technology does not need to support RWX access mode.
* The storage technology must ensure read-after-write consistency. All NAS storage (excluding {gluster-native}/{gluster-external} GlusterFS as it uses an object storage interface) are not
recommended for {product-title} Registry cluster deployment with production workloads.
* While `hostPath` volumes are configurable for a non-scaled/HA {product-title} Registry, they are not recommended for cluster deployment.

==== Scaled registry

In a scaled/HA {product-title} registry cluster deployment:

* The preferred storage technology is object storage. The storage technology must support RWX access mode and must ensure read-after-write consistency.
* File storage and block storage are not recommended for a scaled/HA {product-title} registry cluster deployment with production workloads.
* All NAS storage (excluding {gluster-native}/{gluster-external} GlusterFS as it uses an object storage interface) are
not recommended for {product-title} Registry cluster deployment with production workloads.


==== Metrics

In an {product-title} hosted metrics cluster deployment:

* The preferred storage technology is block storage.
* It is not recommended to use NAS storage (excluding {gluster-native}/{gluster-external} GlusterFS as it uses a block storage interface from iSCSI) for a hosted metrics cluster deployment with production workloads.

[IMPORTANT]
====
Testing shows issues with using the NFS server on RHEL as storage backend for
the container image registry. This includes the Cassandra for metrics storage.
Therefore, using NFS to back PVs used by core services is not recommended.

Other NFS implementations on the marketplace might not have these issues.
Contact the individual NFS implementation vendor for more information on any
testing that was possibly completed against these OpenShift core components.
====

==== Logging

In an {product-title} hosted logging cluster deployment:

* The preferred storage technology is block storage.
* It is not recommended to use NAS storage (excluding {gluster-native}/{gluster-external} GlusterFS as it uses a block storage interface from iSCSI) for a hosted metrics cluster deployment with production workloads.

[IMPORTANT]
====
Testing shows issues with using the NFS server on RHEL as storage backend for
the container image registry. This includes ElasticSearch for logging storage.
Therefore, using NFS to back PVs used by core services is not recommended.

Other NFS implementations on the marketplace might not have these issues.
Contact the individual NFS implementation vendor for more information on any
testing that was possibly completed against these OpenShift core components.
====

==== Applications

Application use cases vary from application to application, as described in the following examples:

* Storage technologies that support dynamic PV provisioning have low mount time latencies, and are not tied
to nodes to support a healthy cluster.
* Application developers are responsible for knowing and understanding the storage
requirements for their application, and how it works with the provided storage
to ensure that issues do not occur when an application scales or interacts
with the storage layer.

=== Other specific application storage recommendations

* {product-title} Internal *etcd*: For the best etcd reliability, the lowest consistent latency storage technology is preferable.
* OpenStack Cinder: OpenStack Cinder tends to be adept in ROX access mode use cases.
* Databases: Databases (RDBMSs, NoSQL DBs, etc.) tend to perform best with dedicated block storage.
